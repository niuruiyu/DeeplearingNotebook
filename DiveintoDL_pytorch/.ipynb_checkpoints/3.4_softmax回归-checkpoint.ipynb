{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89a4df71-4d7b-471b-bd5d-ee94d9fa2875",
   "metadata": {},
   "source": [
    "softmax回归的输出单元从一个变成了多个，更适合离散值的预测和训练，一般用到神经网络中的分类模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cfab40-d986-433e-8abc-0fdaf1184458",
   "metadata": {},
   "source": [
    "这里以一个简单的图像分类为例：\n",
    "输入图像的高和宽均为4像素，色彩为灰度，分析一张图片是狗，猫或鸡  \n",
    "将以上的问题转换：  \n",
    "输入的features：x1,x2,x3,x4\n",
    "输出的labels:y1=1,y2=2,y3=3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8fd075-8635-42a4-a34d-d699a2cf9efc",
   "metadata": {},
   "source": [
    "![note](./images/3.4_1img.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d998e-1ddb-42c8-81a5-cf5836f30dd4",
   "metadata": {},
   "source": [
    "### 交叉熵损失函数\n",
    "根据以上softmax相对于纯粹的线性回归模型，可以更加方便地与离散标签计算误差。  \n",
    "softmax运算的输出（也就是“预测值”）是一个合法的类别预测分布（1*n）的大小的一个向量  \n",
    "那么如何去计算预测值和真实值之间的损失？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2732544c-4c8b-4163-8206-023fd63194b7",
   "metadata": {},
   "source": [
    "可以把真实值也设定为同类型的格式，ex:[0,1,0]对应的label的真实含义是“狗”  \n",
    "那么计算损失函数时就可以像线性回归那样用平方损失函数，先算差再平方  \n",
    "但是事实上，分类任务并不需要预测的概率完全等于标签的概率，只需要真实的类别的概率大大高于其他类别  \n",
    "所以我们使用更加适合的函数：\n",
    "**交叉熵损失函数**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b16ca4c-e669-49a1-8f29-4767b7dc0b6c",
   "metadata": {},
   "source": [
    "![note](./images/3.4_2img.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d6fe51-3031-47b3-883d-f0656bc544db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
