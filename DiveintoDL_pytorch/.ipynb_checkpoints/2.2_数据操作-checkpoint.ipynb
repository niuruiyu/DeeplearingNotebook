{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b74cec7c-50c8-46d5-b8be-328a8643c133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ed97300-917a-4944-b9a2-b66f24e751c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.8333e-12, 1.9898e-42, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "#创建Tensor\n",
    "#创建未初始化的\n",
    "x = torch.empty(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae13a8e7-4288-480f-bdd1-e1c23503e2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6229, 0.4969, 0.6069],\n",
      "        [0.0250, 0.2709, 0.6711],\n",
      "        [0.5550, 0.8540, 0.7255],\n",
      "        [0.4183, 0.7665, 0.5877],\n",
      "        [0.2339, 0.8392, 0.3727]])\n"
     ]
    }
   ],
   "source": [
    "#创建一个随机初始化的tensor\n",
    "x = torch.rand(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13bda299-5820-488d-bee9-18dcd16900a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "#创建一个数据类型为long的tensor\n",
    "x = torch.zeros(5,3,dtype = torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5abdabd9-17bd-49d7-a2be-01f5a1781838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "#直接根据数据创建：\n",
    "x = torch.tensor([5.5,3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff3f4bf7-28db-4c7f-b9b9-554d57b6ceef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[-0.7037,  1.3524, -1.2868]])\n"
     ]
    }
   ],
   "source": [
    "#根据现有的tensor来创建，会默认重用一些属性（like数据类型和device）\n",
    "x = x.new_ones(1,3,dtype=torch.float64)\n",
    "print(x)\n",
    "x = torch.randn_like(x,dtype=torch.float)#这里是重新设定了新的数据类型\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da8383f3-a350-435d-8d62-7824c2e1647c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "#获得tensor的属性\n",
    "#size()和shape都可以得到tensor的形状\n",
    "print(x.size())\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ae850f1-db18-47e9-9e13-900428a94ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.8335e-12, 1.9898e-42, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([ 1.0000,  3.2500,  5.5000,  7.7500, 10.0000])\n",
      "tensor([[0.3906, 0.1573, 0.2274],\n",
      "        [0.0117, 0.7784, 0.1382],\n",
      "        [0.4956, 0.7966, 0.9447],\n",
      "        [0.3798, 0.6612, 0.0925],\n",
      "        [0.3935, 0.5792, 0.8453]])\n"
     ]
    }
   ],
   "source": [
    "#创建TENSOR的方法的总结：\n",
    "#基础构造函数\n",
    "x = torch.Tensor(5,3)\n",
    "print(x)\n",
    "#类似np.array的构造函数\n",
    "x = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(x)\n",
    "#全为1的tensor\n",
    "x = torch.ones(5,3)\n",
    "print(x)\n",
    "#全为0的tensor\n",
    "x = torch.zeros(5,3)\n",
    "print(x)\n",
    "#对角线为1，其他是0\n",
    "x = torch.eye(4,4)\n",
    "print(x)\n",
    "#从s到e，step\n",
    "x = torch.arange(1,10,1)\n",
    "print(x)\n",
    "#从s到e，均匀分成steps份,就是等差数列，包括end\n",
    "x = torch.linspace(1,10,5)\n",
    "print(x)\n",
    "#标准分布（均匀分布）\n",
    "x = torch.rand(5,3)\n",
    "print(x)\n",
    "#还有正态分布：normal(mean,std)\n",
    "#随机排列randperm(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9870578-a3ad-49cd-ad0b-4217d54a56e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8456, 1.1331, 0.9056],\n",
      "        [0.9487, 0.8069, 0.4020],\n",
      "        [1.1159, 1.0189, 1.5479],\n",
      "        [0.9014, 1.1284, 0.5029],\n",
      "        [1.1801, 1.0194, 1.7439]])\n",
      "tensor([[0.8456, 1.1331, 0.9056],\n",
      "        [0.9487, 0.8069, 0.4020],\n",
      "        [1.1159, 1.0189, 1.5479],\n",
      "        [0.9014, 1.1284, 0.5029],\n",
      "        [1.1801, 1.0194, 1.7439]])\n",
      "tensor([[0.8456, 1.1331, 0.9056],\n",
      "        [0.9487, 0.8069, 0.4020],\n",
      "        [1.1159, 1.0189, 1.5479],\n",
      "        [0.9014, 1.1284, 0.5029],\n",
      "        [1.1801, 1.0194, 1.7439]])\n",
      "tensor([[0.8456, 1.1331, 0.9056],\n",
      "        [0.9487, 0.8069, 0.4020],\n",
      "        [1.1159, 1.0189, 1.5479],\n",
      "        [0.9014, 1.1284, 0.5029],\n",
      "        [1.1801, 1.0194, 1.7439]])\n"
     ]
    }
   ],
   "source": [
    "#tensor各种操作\n",
    "#算术操作\n",
    "#加法\n",
    "y = torch.rand(5,3)\n",
    "print(x + y)\n",
    "print(torch.add(x,y))\n",
    "#add还可以指定输出\n",
    "result = torch.empty(5,3)\n",
    "torch.add(x,y,out=result)\n",
    "print(result)\n",
    "#把x加到y上\n",
    "y.add_(x)\n",
    "print(y)\n",
    "#这个是inplace的版本，pytorch的inplace版本都有后缀_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0ab0124-1b43-43dc-a058-5c038e544398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2736, 0.3257, 0.3431])\n",
      "tensor([1.2736, 1.3257, 1.3431])\n",
      "tensor([1.2736, 1.3257, 1.3431])\n"
     ]
    }
   ],
   "source": [
    "#索引\n",
    "#类似numpy\n",
    "x = torch.rand(5,3)\n",
    "print(x[0,:])\n",
    "y = x[0,:]\n",
    "y += 1\n",
    "print(y)\n",
    "print(x[0,:])\n",
    "#这里y+1后x也跟着改了，索引出来的结果会和原始的数据共享内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67f10ab0-390e-4a6e-8693-17f344f01faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2736, 1.3257, 1.3431, 0.2708, 0.1927, 0.2387, 0.8236, 0.9062, 0.6850,\n",
      "        0.5556, 0.5740, 0.0697, 0.4346, 0.8490, 0.0356])\n",
      "tensor([[1.2736, 1.3257, 1.3431],\n",
      "        [0.2708, 0.1927, 0.2387],\n",
      "        [0.8236, 0.9062, 0.6850],\n",
      "        [0.5556, 0.5740, 0.0697],\n",
      "        [0.4346, 0.8490, 0.0356]])\n",
      "tensor([[1.2736, 1.3257, 1.3431, 0.2708, 0.1927],\n",
      "        [0.2387, 0.8236, 0.9062, 0.6850, 0.5556],\n",
      "        [0.5740, 0.0697, 0.4346, 0.8490, 0.0356]])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([15])\n",
      "torch.Size([3, 5])\n",
      "tensor([[2.2736, 2.3257, 2.3431],\n",
      "        [1.2708, 1.1927, 1.2387],\n",
      "        [1.8236, 1.9062, 1.6850],\n",
      "        [1.5556, 1.5740, 1.0697],\n",
      "        [1.4346, 1.8490, 1.0356]])\n",
      "tensor([2.2736, 2.3257, 2.3431, 1.2708, 1.1927, 1.2387, 1.8236, 1.9062, 1.6850,\n",
      "        1.5556, 1.5740, 1.0697, 1.4346, 1.8490, 1.0356])\n",
      "tensor([[2.2736, 2.3257, 2.3431, 1.2708, 1.1927],\n",
      "        [1.2387, 1.8236, 1.9062, 1.6850, 1.5556],\n",
      "        [1.5740, 1.0697, 1.4346, 1.8490, 1.0356]])\n"
     ]
    }
   ],
   "source": [
    "#改变形状\n",
    "y = x.view(15)\n",
    "print(y)\n",
    "print(x)\n",
    "z = y.view(-1,5)\n",
    "print(z)\n",
    "#-1的维度可以根据后面的5计算出来\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(z.shape)\n",
    "#虽然xyz是三个不同的tensor，但是共享数据地址\n",
    "#所以数据改变大小时，三个tensor的值都会改变\n",
    "y +=1\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "737521cb-b813-4318-8fb6-7572f5c2169e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.2736, 2.3257, 2.3431, 1.2708, 1.1927, 1.2387, 1.8236, 1.9062, 1.6850,\n",
      "        1.5556, 1.5740, 1.0697, 1.4346, 1.8490, 1.0356])\n",
      "tensor([[2.2736, 2.3257, 2.3431],\n",
      "        [1.2708, 1.1927, 1.2387],\n",
      "        [1.8236, 1.9062, 1.6850],\n",
      "        [1.5556, 1.5740, 1.0697],\n",
      "        [1.4346, 1.8490, 1.0356]])\n",
      "tensor([1.2736, 1.3257, 1.3431, 0.2708, 0.1927, 0.2387, 0.8236, 0.9062, 0.6850,\n",
      "        0.5556, 0.5740, 0.0697, 0.4346, 0.8490, 0.0356])\n"
     ]
    }
   ],
   "source": [
    "#如果不想共享数据的内存，想要得到一个真正的新的副本\n",
    "#推荐先clone得到一个副本后，再进行维度的更改（view）\n",
    "x_cp = x.clone().view(15)\n",
    "print(x_cp)\n",
    "x_cp -=1\n",
    "print(x)\n",
    "print(x_cp)\n",
    "#用clone的一个好处时：会被记录在计算图中，也就是梯度回传到副本时也会传到源tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13326b95-239d-4085-8a5d-d5a13afe6cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1659])\n",
      "0.16586148738861084\n"
     ]
    }
   ],
   "source": [
    "#item（）将一个标量tensor转换成一个number\n",
    "x = torch.rand(1)\n",
    "print(x)\n",
    "print(x.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6b7e831-4813-4f52-8e70-cd7e6b7a6078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5583, 0.4613, 0.4904, 0.4460, 0.6875],\n",
      "        [0.5987, 0.8590, 0.3391, 0.5321, 0.8142],\n",
      "        [0.4663, 0.4323, 0.8044, 0.2584, 0.2067],\n",
      "        [0.7521, 0.5901, 0.3150, 0.7069, 0.8310],\n",
      "        [0.1385, 0.2221, 0.9599, 0.4063, 0.0639]])\n",
      "tensor(2.9926)\n",
      "tensor([0.5583, 0.8590, 0.8044, 0.7069, 0.0639])\n",
      "tensor([[0.5583, 0.4613, 0.4904, 0.4460, 0.6875],\n",
      "        [0.0000, 0.8590, 0.3391, 0.5321, 0.8142],\n",
      "        [0.0000, 0.0000, 0.8044, 0.2584, 0.2067],\n",
      "        [0.0000, 0.0000, 0.0000, 0.7069, 0.8310],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0639]])\n",
      "tensor([[0.5583, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5987, 0.8590, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4663, 0.4323, 0.8044, 0.0000, 0.0000],\n",
      "        [0.7521, 0.5901, 0.3150, 0.7069, 0.0000],\n",
      "        [0.1385, 0.2221, 0.9599, 0.4063, 0.0639]])\n"
     ]
    }
   ],
   "source": [
    "#线性代数的操作\n",
    "#元素的迹（对角线元素之和）\n",
    "x = torch.rand(5,5)\n",
    "print(x)\n",
    "print(x.trace())\n",
    "#对角线元素\n",
    "print(x.diag())\n",
    "#矩阵的上/下三角\n",
    "print(x.triu())\n",
    "print(x.tril())\n",
    "#矩阵乘法：mm\n",
    "#batch的矩阵乘法：bmm\n",
    "#矩阵运算：addmm，addbmm，addmv，addr，baddbmm……\n",
    "#内积dot\n",
    "#外积：cross\n",
    "#逆矩阵：inverse\n",
    "#奇异值分解svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eda6b88e-6a52-4fb0-9480-c5a0e0feef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensor具有广播机制\n",
    "#上面的加法那里也有体现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c3c81ea-1e69-4f9b-bc54-6c96583f3899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#运算的内存开销\n",
    "# id\n",
    "x = torch.tensor([1,2])\n",
    "y = torch.tensor([3,4])\n",
    "id_before = id(y)\n",
    "y = y+x\n",
    "print(id(y) == id_before)\n",
    "#这里说明进行加法运算后y开辟了新的内存空间\n",
    "#但是索引操作就不会开辟\n",
    "id_before = id(y)\n",
    "y[:] = y+x\n",
    "print(id(y) == id_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d122b6b-eb5a-440a-82dc-eb988f983a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "#tensor转换为numpy\n",
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "print(a)\n",
    "print(b)\n",
    "#同样是共享数据内存\n",
    "b+=1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0e19a37-984d-49e0-95d8-5a6be623a894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#numpy转换为tensor\n",
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(a)\n",
    "print(b)\n",
    "#共享数据内存\n",
    "a+=1\n",
    "print(a)\n",
    "print(b)\n",
    "#所有在CPU上的tensor（除了CharTensor）都支持和numpy数组互相转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15915d27-988d-4795-b424-f66e237e081a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 3. 3. 3. 3.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#numpy变tensor的另一种方法\n",
    "c = torch.tensor(a)\n",
    "#但是这种方法步共享数据内存，而是将数据重新拷贝\n",
    "a+=1\n",
    "print(a)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40e90530-7cd9-45d1-87fc-a51a568702db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([2, 3], device='cuda:0')\n",
      "tensor([2., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#tensor on gpu\n",
    "#to()可以让tensor再CPU和GPU之间相互移动\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    y = torch.ones_like(x,device=device)#创建一个在GPU上的tensor\n",
    "    x = x.to(device)\n",
    "    z = x+y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\",torch.double))，#顺便还可以修改数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9d1b0d-747b-4925-83d7-a9f28beebe28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
