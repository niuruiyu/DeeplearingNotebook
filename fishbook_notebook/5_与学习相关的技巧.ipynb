{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac43a894-3e04-4b3f-b46b-031e6a28b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#本书前面的内容和后面的内容在1.中都已经学习过，这里略过（直接去看网课就可以）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b81f75-14ab-466e-9834-baa38a2a8f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#此处对应第六章与学习相关的技巧\n",
    "#optimizer的取值可以是：SGD，Momentum，AdaGrad，Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1dd27c-d9f8-4fc8-8dbd-9fc026e20970",
   "metadata": {},
   "source": [
    "<!-- Momentum引入物理量速度的概念来控制参数更新时的跨度大小\n",
    "在需要更新快的时候更新的较快，在需要慢的时候更新较慢 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a20745b-f71a-49ec-8ea1-c69f8b0dd5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Momentum引入速度的概念，像实际生活中的一样，在不同的地方更新的跨度不一样\n",
    "# AdaGrad为不同的参数设置不同的学习率，更精准地更新每一个参数\n",
    "# Adam融合以上两种方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17809539-edab-4f5c-bef5-efe29130c69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#后面还有过拟合,正则化,dropout等的介绍,同样略过(之前有了解过)\n",
    "#与学习相关的技巧这一部分观看李宏毅老师的机器学习与深度学习会更加好理解."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5b132c-61c2-4862-916a-1f0aea9da4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这本书后面的部分涉及到卷积神经网络,可以直接看我在第一部分的内容,比较完善."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
